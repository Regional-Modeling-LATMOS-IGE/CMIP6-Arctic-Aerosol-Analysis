{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMIP6 Arctic Case Study : Compute the aerosol-cloud interaction effective radiative forcing\n",
    "\n",
    "--- \n",
    "\n",
    "## What this notebook holds :\n",
    "\n",
    "---\n",
    "\n",
    "<span style=\"color:red\">**It is recommended to first run the *get_cmip6_data.ipynb* notebook to download and prepare the raw model's outputs data for the analysis.**</span>\n",
    "\n",
    "This notebook aims at showing the effective radiative forcing that is caused by the aerosol burdens' levels of 2014 in the shortwabe. It aims at evaluating the different components of the aerosol-cloud's interaction impact on the Arctic warming. This is done using a subset of the CMIP6 model ensemble and using the APRP method devised by *Taylor and al. (2007)* and whose implementation was done by *Zelinka and al. (2023)*. \n",
    "\n",
    "The subset used is described in the github repository and is the one used by *Zelinka and al.*. It can be found in details in the *load_cmip6* submodule as the case described by *ZELINKA-SW* in the *set_search_criterias* function. \n",
    "\n",
    "### The use of CMIP6 data\n",
    "\n",
    "We use two experiments realized during the CMIP6  : **piClim-control** and **piClim-aer**. These are both atmosphere-only climate model simulations in which sea surface temperatures (SSTs) and sea icea concentrations (SICs) are fixed at model-specific preindustrial climatological values. The description of the experiments can be found here : https://wcrp-cmip.github.io/CMIP6_CVs/docs/CMIP6_experiment_id.html. On the one hand, the **piClim-control** realization assumes aerosols burdens set to their preindustrial levels hence why it is dubbed as the control experiment. On the other hand, the **piClim-aer** realization uses present-day, present-day being 2014, aerosols burdens' levels.\n",
    "\n",
    "The variable used are listed and explicited below according to : https://clipc-services.ceda.ac.uk/dreq/mipVars.html. All the variables are monthly timeseries over 30 years. We use the monthly climatology of each of these variables.\n",
    "\n",
    "> <span style=\"color:SkyBlue\">**clt**</span>  : Total cloud area fraction (%) for the whole atmospheric column\n",
    ">\n",
    "> <span style=\"color:gold\">**rsdt**</span> : Shortwave radiation ($W/m^{2}$) **incident** at the TOA\n",
    "> \n",
    "> <span style=\"color:orange\">**rsut**</span> : Shortwave radiation ($W/m^{2}$) **going out**  at the TOA\n",
    ">\n",
    "> <span style=\"color:orangered\">**rsutcs**</span> : Shortwave radiation ($W/m^{2}$) **going out**  at TOA for **clear-sky conditions**\n",
    "> \n",
    "> <span style=\"color:Orchid\">**rsds**</span> : Shortwave **downwelling** radiation ($W/m^{2}$) at the surface\n",
    "> \n",
    "> <span style=\"color:Indigo \">**rsdscs**</span>  : Shortwave **downwelling** radiation ($W/m^{2}$) at the surface for **clear-sky conditions**\n",
    "> \n",
    "> <span style=\"color:YellowGreen\">**rsus**</span> : Shortwave **upwelling** radiation ($W/m^{2}$) at the surface\n",
    ">\n",
    "> <span style=\"color:Darkgreen\">**rsuscs**</span>: Shortwave **upwelling** radiation ($W/m^{2}$) at the surface for **clear-sky conditions**\n",
    ">\n",
    "> **areacella** : For every grid, the latitude-dependent surface associated to each grid point.\n",
    "\n",
    "### Approximate Partial Radiative Perturbation\n",
    "\n",
    "**TO WRITE...**\n",
    "\n",
    "## References : \n",
    "\n",
    "### APRP method\n",
    "\n",
    "Taylor, K. E., M. Crucifix, P. Braconnot, C. D. Hewitt, C. Doutriaux, A. J. Broccoli, J. F. B. Mitchell, and M. J. Webb, 2007: Estimating Shortwave Radiative Forcing and Response in Climate Models. J. Climate, 20, 2530–2543, https://doi.org/10.1175/JCLI4143.1. \n",
    "\n",
    "### APRP module used for our analysis\n",
    "\n",
    "https://github.com/mzelinka/aprp\n",
    "\n",
    "Zelinka, M. D., Smith, C. J., Qin, Y., and Taylor, K. E.: Comparison of methods to estimate aerosol effective radiative forcings in climate models, Atmos. Chem. Phys., 23, 8879–8898, https://doi.org/10.5194/acp-23-8879-2023, 2023.\n",
    "\n",
    "### Author\n",
    "\n",
    "Giboni Lucas, 1st year PhD Candidate at IGE (CNRS), Grenoble.\n",
    "\n",
    "https://github.com/gibonil/gibonil\n",
    "\n",
    "### License\n",
    "\n",
    "Feel free to share, use and improve the following code according to the provided license on the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Initialisation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================ IMPORTATIONS ================ #\n",
    "\n",
    "### LOAD AND NAVIGATE THROUGH THE DATA ###\n",
    "\n",
    "import os  # to get access to commands related to path setting and creation of directories\n",
    "\n",
    "### DATA OBJECTS AND ASSOCIATED COMPUTATION ###\n",
    "\n",
    "import numpy as np  # to handle numpy arrays and the associated tools\n",
    "\n",
    "import xarray as xr  # to manage the data\n",
    "\n",
    "import xcdat as xc  # to handle climate model outputs with xarray\n",
    "\n",
    "### REPRESENTING DATA ###\n",
    "\n",
    "import matplotlib.pyplot as plt  # to handle plotting routines\n",
    "\n",
    "import cartopy.crs as ccrs  # to handle map projections\n",
    "\n",
    "### HOMEMADE LIBRARIES ###\n",
    "\n",
    "## Load the climatology dictionary ##\n",
    "\n",
    "from utilities.get_cmip6_data.store_data.dict_netcdf_transform import (\n",
    "    netcdf_to_dict, # to load the climatology dictionary\n",
    ")  \n",
    "\n",
    "### APRP LIBRARY ###\n",
    "\n",
    "from utilities.aprp_library.code.aprp import(\n",
    "    APRP, # APRP method\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the paths for saving and loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, the user needs to define the paths at which will be downloaded the data and saved the climatologies if necessary. They also need to define the path to the table associating the monthly climatologies netcdf files with their respective key in the climatologies' dictionary to be loaded.\n",
    "\n",
    "If *get_cmip6_data.ipynb* notebook was run before, then only the path to the *key_paths_table.pkl* file is relevant here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================ DEFINE THE FOLDERS WHERE IS STORED THE DATA ================ #\n",
    "\n",
    "### DEFINE THE HOME DIRECTORY ###\n",
    "\n",
    "## Home directory ##\n",
    "\n",
    "homedir_path = os.path.expanduser(\"~\")\n",
    "\n",
    "### DEFINE WHERE TO DOWNLOAD THE RAW DATA ###\n",
    "\n",
    "## Parent directory of the download folder ##\n",
    "\n",
    "parent_path_download = homedir_path + \"/certainty-data\"\n",
    "\n",
    "## Name of the download folder ##\n",
    "\n",
    "download_folder_name = \"CMIP6-DATA\"\n",
    "\n",
    "### DEFINE WHERE TO SAVE THE CLIMATOLOGIES ###\n",
    "\n",
    "## Path of the save directory ##\n",
    "\n",
    "parent_path_save_clim = (\n",
    "    homedir_path + \"/certainty-data/\" + download_folder_name + \"/climatologies\"\n",
    ")\n",
    "\n",
    "### DEFINE WHERE TO LOOK FOR THE TABLE OF THE CLIMATOLOGIES' PATHS ###\n",
    "\n",
    "table_path = parent_path_save_clim + \"/table\" + \"/key_paths_table.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the CMIP6 climatology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the CMIP6 climatology. We first check the existence of the *key_paths_table.pkl* file that indicate that the *get_cmip6_data.ipynb* notebook was successfully run. Otherwise, we launch the full routine to download the raw data and generate the climatologies. These paths are the absolute paths from the home directory.\n",
    "\n",
    "**This full routine lasts about 2 hours if no download was done before.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The monthly climatologies were generated and can be retrieved\n"
     ]
    }
   ],
   "source": [
    "# ================ LOAD THE MONTHLY CLIMATOLOGIES ================ #\n",
    "\n",
    "### CHECK IF THE CLIMATOLOGIES WERE GENERATED BEFORE ###\n",
    "\n",
    "if os.path.lexists(path = table_path) :\n",
    "\n",
    "    ## The table exists we can therefore load the dictionary of the climatologies ## \n",
    "\n",
    "    print(\"The monthly climatologies were generated and can be retrieved\")\n",
    "\n",
    "    data_cmip6_clim = netcdf_to_dict(save_path=parent_path_save_clim)\n",
    "\n",
    "else :\n",
    "\n",
    "    ## The table does not exist : we need to download the data and prepare it ##\n",
    "\n",
    "    print(\"No key_paths_table.pkl at the given path.\\n\" \\\n",
    "    \"We download the data and create the monthly climatologies dictionary\")\n",
    "\n",
    "    # We import the necessary submodule #\n",
    "\n",
    "    from utilities.get_cmip6_data.prepare_data.extract_climatologies import (\n",
    "    create_climatology_dict,  # to create the climatology dictionary and save it\n",
    "    )\n",
    "\n",
    "    ## Create the climatologies dictionary ##\n",
    "\n",
    "    create_climatology_dict(\n",
    "    data_path = parent_path_download,\n",
    "    data_folder_name = download_folder_name,\n",
    "    save_path = parent_path_save_clim,\n",
    "    selected_case = \"ZELINKA-SW\",\n",
    ")\n",
    "    \n",
    "    ## Load it ##\n",
    "\n",
    "    data_cmip6_clim = netcdf_to_dict(save_path=parent_path_save_clim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APRP METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_keys = list(data_cmip6_clim.keys())\n",
    "\n",
    "clim_keys_without_exp = [\n",
    "    get_model_entries__only_from_clim(key_with_exp) for key_with_exp in clim_keys\n",
    "]\n",
    "\n",
    "\n",
    "# np.unique(clim_keys_without_exp) + \".piClim-control\"\n",
    "\n",
    "# np.unique(clim_keys_without_exp) + \".piClim-aer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_aprp = {}\n",
    "\n",
    "for key in clim_keys_without_exp:\n",
    "\n",
    "    key_control = key + \".piClim-control\"\n",
    "\n",
    "    key_aer = key + \".piClim-aer\"\n",
    "\n",
    "    output = APRP(data_cmip6_clim[key_control], data_cmip6_clim[key_aer])\n",
    "\n",
    "    dict_aprp[key] = output\n",
    "\n",
    "# add units to lat when building the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_aprp[clim_keys_without_exp[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when to regrid ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRIDDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create output grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.typing as npt\n",
    "\n",
    "\n",
    "def get_step(coordinate_array: npt.NDArray[np.float64]) -> float:\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    return np.max(np.diff(coordinate_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_steps_lat = [get_step(dict_aprp[key].lat.values) for key in clim_keys_without_exp]\n",
    "\n",
    "list_steps_lon = [get_step(dict_aprp[key].lon.values) for key in clim_keys_without_exp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_step_lon = np.max(list_steps_lon)\n",
    "\n",
    "max_step_lat = np.max(list_steps_lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to have a regular grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "n_steps_lon = floor(360 / max_step_lon)  # bc we want a step greater than max_step_lat\n",
    "\n",
    "new_step_lon = 360 / n_steps_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_lat = floor(180 / max_step_lat)  # bc we want a step greater than max_step_lat\n",
    "\n",
    "new_step_lat = 180 / n_steps_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(90 - new_step_lat / 2) - (-90 + new_step_lat / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_axis = xc.create_axis(\n",
    "    \"lat\", np.arange(-90 + new_step_lat / 2, 90 + new_step_lat / 2, new_step_lat)\n",
    ")\n",
    "\n",
    "# since we have peaked the step such that the latitude range is divded into an integer number of intervals we may center its bounds on -90 / 90.\n",
    "\n",
    "lon_axis = xc.create_axis(\"lon\", np.arange(0, 360, new_step_lon))\n",
    "\n",
    "output_grid = xc.create_grid(x=lon_axis, y=lat_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If performing conservative regridding from a high/medium resolution lat/lon grid to a coarse lat/lon target, Regrid2 may provide better results as it assumes grid cells with constant latitudes and longitudes while xESMF assumes the cells are connected by Great Circles : https://xcdat.readthedocs.io/en/latest/generated/xarray.Dataset.regridder.horizontal.html\n",
    "\n",
    "\n",
    "BASE ARRAY NO VALUE AT THE POLES ??? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ds.regridder.horizontal(\"sfc_alb\", output_grid, tool=\"regrid2\")\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(16, 4))\n",
    "\n",
    "ds.sfc_alb.isel(time=0).plot(\n",
    "    ax=axes[0], vmin=-40, vmax=40, extend=\"both\", cmap=\"RdBu_r\"\n",
    ")\n",
    "\n",
    "output.sfc_alb.isel(time=0).plot(\n",
    "    ax=axes[1], vmin=-40, vmax=40, extend=\"both\", cmap=\"RdBu_r\"\n",
    ")\n",
    "axes[1].set_title(\"Output data\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_step_lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extraire une même variable, regrid toute la variable et combiner sur le nb de modèles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_field(ds, field: str):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    field_regridded = ds.regridder.horizontal(field, output_grid, tool=\"regrid2\")\n",
    "\n",
    "    return field_regridded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_aprp = dict_aprp.keys()\n",
    "\n",
    "\n",
    "fields = [\n",
    "    \"cld\",\n",
    "    \"sfc_alb\",\n",
    "    \"noncld\",\n",
    "    \"noncld_scat\",\n",
    "    \"noncld_abs\",\n",
    "    \"cld_amt\",\n",
    "    \"cld_scat\",\n",
    "    \"cld_abs\",\n",
    "]\n",
    "\n",
    "# initialize\n",
    "\n",
    "field = \"cld\"\n",
    "\n",
    "dict_aprp_regridded_full = {\n",
    "    key: dict_aprp[key].regridder.horizontal(field, output_grid, tool=\"regrid2\")\n",
    "    for key in keys_aprp\n",
    "}\n",
    "\n",
    "\n",
    "for field in fields[1:]:\n",
    "\n",
    "    # generate the dictionnary of all models for one field\n",
    "\n",
    "    dict_aprp_regridded_given_field = {\n",
    "        key: dict_aprp[key].regridder.horizontal(field, output_grid, tool=\"regrid2\")\n",
    "        for key in keys_aprp\n",
    "    }\n",
    "\n",
    "    # add this one field to the full dictionnary\n",
    "\n",
    "    dict_aprp_regridded_full = {\n",
    "        key: add_one_variable_to_dataset(\n",
    "            variable_name=field,\n",
    "            var_datarray=dict_aprp_regridded_given_field[key],\n",
    "            modify_data=True,\n",
    "            dataset=dict_aprp_regridded_full[key],\n",
    "        )\n",
    "        for key in keys_aprp\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_aprp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_aprp = [\n",
    "    \"BCC-ESM1.r1i1p1f1\",\n",
    "    \"UKESM1-0-LL.r1i1p1f4\",\n",
    "    \"CanESM5.r1i1p2f1\",\n",
    "    \"CNRM-CM6-1.r1i1p1f2\",\n",
    "    \"CNRM-ESM2-1.r1i1p1f2\",\n",
    "    \"ACCESS-ESM1-5.r1i1p1f1\",\n",
    "    \"MPI-ESM-1-2-HAM.r1i1p1f1\",\n",
    "    \"IPSL-CM6A-LR.r1i1p1f1\",\n",
    "    \"IPSL-CM6A-LR-INCA.r1i1p1f1\",\n",
    "    \"MIROC6.r1i1p1f1\",\n",
    "    \"MRI-ESM2-0.r1i1p1f1\",\n",
    "    \"GISS-E2-1-G.r1i1p1f1\",\n",
    "    \"CESM2.r1i1p1f1\",\n",
    "    \"NorESM2-LM.r1i1p1f1\",\n",
    "    \"NorESM2-MM.r1i1p1f1\",\n",
    "    \"GFDL-CM4.r1i1p1f1\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed for the concat function to work\n",
    "\n",
    "dict_aprp_regridded_full = {\n",
    "    key: dict_aprp_regridded_full[key]\n",
    "    .groupby(dict_aprp_regridded_full[key].time.dt.month)\n",
    "    .mean()\n",
    "    for key in keys_aprp\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make the entry average\n",
    "\n",
    "ensemble_aprp_avg = xr.concat(dict_aprp_regridded_full.values(), \"entry\").mean(\n",
    "    dim=\"entry\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT MAP OF APRP COMPONENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ensemble_aprp_avg\n",
    "\n",
    "fields = [\n",
    "    \"cld\",\n",
    "    \"sfc_alb\",\n",
    "    \"noncld\",\n",
    "    \"noncld_scat\",\n",
    "    \"noncld_abs\",\n",
    "    \"cld_amt\",\n",
    "    \"cld_scat\",\n",
    "    \"cld_abs\",\n",
    "]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "plt.suptitle(\"APRP Components\", fontsize=16, x=0, ha=\"left\")\n",
    "axes = fig.subplots(nrows=4, ncols=2, subplot_kw={\"projection\": ccrs.Robinson()})\n",
    "cnt = -1\n",
    "for row in range(4):\n",
    "    for col in range(2):\n",
    "        cnt += 1\n",
    "        var = fields[cnt]\n",
    "        avgmap = output.mean(\"month\")\n",
    "        avg = avgmap.spatial.average(var, axis=[\"X\", \"Y\"])[var].values\n",
    "        pl = avgmap[var].plot(\n",
    "            ax=axes[row, col],\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            vmin=-7.5,\n",
    "            vmax=7.5,\n",
    "            cmap=\"RdBu_r\",\n",
    "            add_colorbar=False,\n",
    "        )\n",
    "        axes[row, col].set_title(var + \" (\" + str(np.round(avg, 3)) + \")\")\n",
    "        axes[row, col].coastlines()\n",
    "\n",
    "plt.tight_layout(w_pad=2.5, h_pad=-2)\n",
    "\n",
    "fig.colorbar(\n",
    "    pl, ax=axes.ravel().tolist(), pad=0.02, shrink=0.5, aspect=15, label=\"W/m$^2$\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cmip6-analysis]",
   "language": "python",
   "name": "conda-env-cmip6-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
