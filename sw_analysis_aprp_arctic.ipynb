{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMIP6 Arctic Case Study : Compute the aerosol-cloud interaction effective radiative forcing\n",
    "\n",
    "## What this notebook holds \n",
    "\n",
    "This notebook aims at showing the effective radiative forcing that is caused by the aerosol burdens' levels of 2014.\n",
    "\n",
    "### The use of CMIP6 data\n",
    "\n",
    "We use two experiments realized during the CMIP6  : **piClim-control** and **piClim-aer**. These are both atmosphere-only climate model simulations in which sea surface temperatures (SSTs) and sea icea concentrations (SICs) are fixed at model-specific preindustrial climatological values. The description of the experiments can be found here : https://wcrp-cmip.github.io/CMIP6_CVs/docs/CMIP6_experiment_id.html. On the one hand, the **piClim-control** realization assumes aerosols burdens set to their preindustrial levels hence why it is dubbed as the control experiment. On the other hand, the **piClim-aer** realization uses present-day, present-day being 2014, aerosols burdens' levels.\n",
    "\n",
    "The variable used are listed and explicited below according to : https://clipc-services.ceda.ac.uk/dreq/mipVars.html. All the variables are monthly timeseries over 30 years. We use the monthly climatology of each of these variables.\n",
    "\n",
    "> <span style=\"color:SkyBlue\">**clt**</span>  : Total cloud area fraction (%) for the whole atmospheric column\n",
    ">\n",
    "> <span style=\"color:gold\">**rsdt**</span> : Shortwave radiation ($W/m^{2}$) **incident** at the TOA\n",
    "> \n",
    "> <span style=\"color:orange\">**rsut**</span> : Shortwave radiation ($W/m^{2}$) **going out**  at the TOA\n",
    ">\n",
    "> <span style=\"color:orangered\">**rsutcs**</span> : Shortwave radiation ($W/m^{2}$) **going out**  at TOA for **clear-sky conditions**\n",
    "> \n",
    "> <span style=\"color:Orchid\">**rsds**</span> : Shortwave **downwelling** radiation ($W/m^{2}$) at the surface\n",
    "> \n",
    "> <span style=\"color:Indigo \">**rsdscs**</span>  : Shortwave **downwelling** radiation ($W/m^{2}$) at the surface for **clear-sky conditions**\n",
    "> \n",
    "> <span style=\"color:YellowGreen\">**rsus**</span> : Shortwave **upwelling** radiation ($W/m^{2}$) at the surface\n",
    ">\n",
    "> <span style=\"color:Darkgreen\">**rsuscs**</span>: Shortwave **upwelling** radiation ($W/m^{2}$) at the surface for **clear-sky conditions**\n",
    ">\n",
    "> **areacella** : For every grid, the latitude-dependent surface associated to each grid point.\n",
    "\n",
    "### APRP METHOD FOR THE SW\n",
    "\n",
    "**TO WRITE...**\n",
    "\n",
    "Done by Lucas Giboni.\n",
    "\n",
    "Reference :\n",
    "\n",
    "Taylor, K. E., M. Crucifix, P. Braconnot, C. D. Hewitt, C. Doutriaux, A. J. Broccoli, J. F. B. Mitchell, and M. J. Webb, 2007: Estimating Shortwave Radiative Forcing and Response in Climate Models. J. Climate, 20, 2530–2543, https://doi.org/10.1175/JCLI4143.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Initialisation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD AND NAVIGATE THROUGH THE DATA ###\n",
    "\n",
    "import os  # to get access to commands related to path setting and creation of directories\n",
    "\n",
    "### DATA OBJECTS AND ASSOCIATED COMPUTATION ###\n",
    "\n",
    "import numpy as np  # to handle numpy arrays and the associated tools\n",
    "\n",
    "import xarray as xr  # to manage the data\n",
    "\n",
    "import xcdat as xc  # to handle climate model outputs with xarray\n",
    "\n",
    "### REPRESENTING DATA ###\n",
    "\n",
    "import matplotlib.pyplot as plt  # to handle plotting routines\n",
    "\n",
    "import cartopy.crs as ccrs  # to handle map projections\n",
    "\n",
    "### HOMEMADE LIBRARIES ###\n",
    "\n",
    "from utilities.prepare_data.extract_climatologies import (\n",
    "    create_climatology_dict,\n",
    "    get_model_entries__only_from_clim,\n",
    "    add_one_variable_to_dataset,\n",
    ")  # functions to create the climatology dictionnary from the raw data\n",
    "\n",
    "from utilities.aprp_library.code.aprp import APRP  # APRP routine\n",
    "\n",
    "from utilities.store_data.save_and_load_data import (\n",
    "    netcdf_to_dict,\n",
    ")  # to load the climatology dictionnary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the paths for saving and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#### INITIALISATION ###\n",
    "#######################\n",
    "\n",
    "# ================ DEFINE THE FOLDERS WHERE IS STORED THE DATA ================ #\n",
    "\n",
    "### DEFINE THE HOME DIRECTORY ###\n",
    "\n",
    "## Home directory ##\n",
    "\n",
    "homedir_path = os.path.expanduser(\"~\")\n",
    "\n",
    "### DEFINE WHERE IS THE DOWNLOADED RAW DATA ###\n",
    "\n",
    "## Parent directory of the download folder ##\n",
    "\n",
    "parent_path_download = homedir_path + \"/certainty-data\"\n",
    "\n",
    "## Name of the download folder ##\n",
    "\n",
    "download_folder_name = \"CMIP6-DATA\"\n",
    "\n",
    "### DEFINE WHERE TO SAVE THE CLIMATOLOGIES ###\n",
    "\n",
    "## Path of the save directory ##\n",
    "\n",
    "parent_path_save_clim = (\n",
    "    homedir_path + \"/certainty-data/\" + download_folder_name + \"/climatologies\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the CMIP6 climatology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check wether the clim exists or not ?\n",
    "\n",
    "key_paths_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_paths_table = pd.read_pickle(\n",
    "    parent_path_save_clim + \"/table/\" + \"key_paths_table.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "key_paths_table\n",
    "compare both\n",
    "new_simpler_key_given_exp\n",
    "\n",
    "devise a new function\n",
    "\n",
    "+ devise a function to do properly the regridding for the intensive variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HOMEMADE LIBRARIES ###\n",
    "\n",
    "from utilities.download.load_cmip6 import loading_cmip6  # function to load the raw data\n",
    "\n",
    "from utilities.store_data.save_and_load_data import (\n",
    "    dict_to_netcdf,\n",
    ")  # function to save the generated climatology\n",
    "\n",
    "# ================ SEARCH CRITERIAS FOR OUR ANALYSIS ================ #\n",
    "\n",
    "from utilities.download.load_cmip6 import (\n",
    "    variable_id,\n",
    ")  # variable search criteria globally defined in load_cmip6\n",
    "\n",
    "from utilities.prepare_data.extract_climatologies import (\n",
    "    generate_per_model_dict_key,\n",
    "    get_model_entries__only_from_clim,\n",
    "    add_one_variable_to_dataset,\n",
    ")  # functions to create the climatology dictionnary from the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_climatology_dict(\n",
    "    data_path: str, data_folder_name: str, save_path: str, do_we_clear: bool = True\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    ---\n",
    "\n",
    "    ### DEFINITION\n",
    "\n",
    "    This function generates the dictionnary of the xarray datasets holding every monthly climatology of the loaded raw variables.\n",
    "    It then saves it as netcdf files for the provided save_path within the folder named save_folder_name.\n",
    "\n",
    "    ---\n",
    "\n",
    "    ### INPUTS\n",
    "\n",
    "    DATA_PATH : STR | path of the parent directory of the raw data folder\n",
    "\n",
    "    DATA_FOLDER_NAME : STR | name of the raw data folder\n",
    "\n",
    "    SAVE_PATH : STR | path of the directory of the save folder\n",
    "\n",
    "    DO_WE_CLEAR : BOOL | option to clear the save folder if it already exists : default is True\n",
    "\n",
    "    ---\n",
    "\n",
    "    ### OUTPUTS\n",
    "\n",
    "    nothing.\n",
    "\n",
    "    ---\n",
    "    \"\"\"\n",
    "\n",
    "    ### INITIALIZATION ###\n",
    "\n",
    "    ## Load the raw data ##\n",
    "\n",
    "    dict_cmip6, dict_areacella = loading_cmip6(\n",
    "        parent_path=data_path,\n",
    "        downloading_folder_name=data_folder_name,\n",
    "        do_we_clear=False,\n",
    "    )\n",
    "\n",
    "    print(\"Data dictionnary loaded\\n\")\n",
    "\n",
    "    ## Create the dictionnary ##\n",
    "\n",
    "    print(\"Generating the climatologies' dictionnary\\n\")\n",
    "\n",
    "    dict_cmip6_clim = {}\n",
    "\n",
    "    ## Generate the general key associated to each model.variant and experiment ##\n",
    "\n",
    "    keys_without_variable_unique = generate_per_model_dict_key(dict_cmip6)\n",
    "\n",
    "    ### GO THROUGH EACH MODEL.VARIANT AND EXPERIMENT ###\n",
    "\n",
    "    for key in keys_without_variable_unique:\n",
    "\n",
    "        ## Initialize the dataset with the first variable ##\n",
    "\n",
    "        # Define the variable #\n",
    "\n",
    "        var = variable_id[0]\n",
    "\n",
    "        # Define that the dataset does not exist yet #\n",
    "\n",
    "        modify_data = False\n",
    "\n",
    "        # Copy the key without variable #\n",
    "\n",
    "        key_with_var = key\n",
    "\n",
    "        # Add the variable name #\n",
    "\n",
    "        key_with_var[-2] = var\n",
    "\n",
    "        # Generate the key by joining the str list with \".\" #\n",
    "\n",
    "        key_with_var_full = \".\".join(key_with_var)\n",
    "\n",
    "        # Retrieve the variable data array #\n",
    "\n",
    "        var_datarray = dict_cmip6[key_with_var_full]\n",
    "\n",
    "        # Generate or update the dataset for the given model.variant and experiment #\n",
    "\n",
    "        dataset_given_exp = add_one_variable_to_dataset(\n",
    "            variable_name=var,\n",
    "            var_datarray=var_datarray,\n",
    "            modify_data=modify_data,\n",
    "            do_clim=True,\n",
    "        )\n",
    "\n",
    "        # Set that now the dataset already exists #\n",
    "\n",
    "        modify_data = True\n",
    "\n",
    "        ## Go through the rest of the variables ##\n",
    "\n",
    "        for var in variable_id[1:]:\n",
    "\n",
    "            # Copy the key without variable #\n",
    "\n",
    "            key_with_var = key\n",
    "\n",
    "            # Add the variable name #\n",
    "\n",
    "            key_with_var[-2] = var\n",
    "\n",
    "            # Generate the key by joining the str list with \".\" #\n",
    "\n",
    "            key_with_var_full = \".\".join(key_with_var)\n",
    "\n",
    "            # Retrieve the variable data array #\n",
    "\n",
    "            var_datarray = dict_cmip6[key_with_var_full]\n",
    "\n",
    "            # Update the dataset with the climatology of this variable #\n",
    "\n",
    "            add_one_variable_to_dataset(\n",
    "                variable_name=var,\n",
    "                var_datarray=var_datarray,\n",
    "                modify_data=modify_data,\n",
    "                dataset=dataset_given_exp,\n",
    "                do_clim=True,\n",
    "            )\n",
    "\n",
    "        ## Generate a new simpler key for dict_cmip6_clim ##\n",
    "\n",
    "        # Retrieving the key information #\n",
    "\n",
    "        source_id = key[2]\n",
    "\n",
    "        experiment_id = key[3]\n",
    "\n",
    "        member_id = key[4]\n",
    "\n",
    "        grid_label = key[-1]\n",
    "\n",
    "        # Create the new key #\n",
    "\n",
    "        new_simpler_key_given_exp = \".\".join([source_id, member_id, experiment_id])\n",
    "\n",
    "        ## Use the gathered information to get the areacella entry of the given model.variant and experiment ##\n",
    "\n",
    "        # Build the areacella key #\n",
    "\n",
    "        key_areacella = \".\".join([source_id, member_id, grid_label])\n",
    "\n",
    "        # Retrieve the given areacella #\n",
    "\n",
    "        areacella_datarray = dict_areacella[key_areacella]\n",
    "\n",
    "        # Update the dataset of the given model.variant and experiment with the associated areacella #\n",
    "\n",
    "        # test wether this works ?\n",
    "        \"\"\"\n",
    "        dataset_given_exp[\"areacella\"] = (\n",
    "            (\"lat\", \"lon\"),\n",
    "            areacella_datarray[\"areacella\"].values,\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "        add_one_variable_to_dataset(\n",
    "            variable_name=\"areacella\",\n",
    "            var_datarray=areacella_datarray,\n",
    "            modify_data=modify_data,\n",
    "            dataset=dataset_given_exp,\n",
    "        )\n",
    "\n",
    "        ## Add the dataset to the output dictionnary ##\n",
    "\n",
    "        dict_cmip6_clim[new_simpler_key_given_exp] = dataset_given_exp\n",
    "\n",
    "        ### SAVE THE GENERATED DICTIONNARY ###\n",
    "\n",
    "        dict_to_netcdf(\n",
    "            dataset_dict=dict_cmip6_clim, save_path=save_path, do_we_clear=True\n",
    "        )\n",
    "\n",
    "    print(\"Saving the climatologies' dictionnary\\n\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "### GENERATE CMIP6 CLIMATOLOGY ###\n",
    "##################################\n",
    "\"\"\"\n",
    "create_climatology_dict(data_path = parent_path_download, data_folder_name = download_folder_name,\n",
    "                        save_path = parent_path_save_clim)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the CMIP6 climatology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "### LOAD THE CMIP6 CLIMATOLOGY ###\n",
    "##################################\n",
    "\n",
    "data_cmip6_clim = netcdf_to_dict(save_path=parent_path_save_clim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APRP METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_keys = list(data_cmip6_clim.keys())\n",
    "\n",
    "clim_keys_without_exp = [\n",
    "    get_model_entries__only_from_clim(key_with_exp) for key_with_exp in clim_keys\n",
    "]\n",
    "\n",
    "\n",
    "# np.unique(clim_keys_without_exp) + \".piClim-control\"\n",
    "\n",
    "# np.unique(clim_keys_without_exp) + \".piClim-aer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_aprp = {}\n",
    "\n",
    "for key in clim_keys_without_exp:\n",
    "\n",
    "    key_control = key + \".piClim-control\"\n",
    "\n",
    "    key_aer = key + \".piClim-aer\"\n",
    "\n",
    "    output = APRP(data_cmip6_clim[key_control], data_cmip6_clim[key_aer])\n",
    "\n",
    "    dict_aprp[key] = output\n",
    "\n",
    "# add units to lat when building the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_aprp[clim_keys_without_exp[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when to regrid ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRIDDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create output grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.typing as npt\n",
    "\n",
    "\n",
    "def get_step(coordinate_array: npt.NDArray[np.float64]) -> float:\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    return np.max(np.diff(coordinate_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_steps_lat = [get_step(dict_aprp[key].lat.values) for key in clim_keys_without_exp]\n",
    "\n",
    "list_steps_lon = [get_step(dict_aprp[key].lon.values) for key in clim_keys_without_exp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_step_lon = np.max(list_steps_lon)\n",
    "\n",
    "max_step_lat = np.max(list_steps_lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to have a regular grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "n_steps_lon = floor(360 / max_step_lon)  # bc we want a step greater than max_step_lat\n",
    "\n",
    "new_step_lon = 360 / n_steps_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_lat = floor(180 / max_step_lat)  # bc we want a step greater than max_step_lat\n",
    "\n",
    "new_step_lat = 180 / n_steps_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(90 - new_step_lat / 2) - (-90 + new_step_lat / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_axis = xc.create_axis(\n",
    "    \"lat\", np.arange(-90 + new_step_lat / 2, 90 + new_step_lat / 2, new_step_lat)\n",
    ")\n",
    "\n",
    "# since we have peaked the step such that the latitude range is divded into an integer number of intervals we may center its bounds on -90 / 90.\n",
    "\n",
    "lon_axis = xc.create_axis(\"lon\", np.arange(0, 360, new_step_lon))\n",
    "\n",
    "output_grid = xc.create_grid(x=lon_axis, y=lat_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If performing conservative regridding from a high/medium resolution lat/lon grid to a coarse lat/lon target, Regrid2 may provide better results as it assumes grid cells with constant latitudes and longitudes while xESMF assumes the cells are connected by Great Circles : https://xcdat.readthedocs.io/en/latest/generated/xarray.Dataset.regridder.horizontal.html\n",
    "\n",
    "\n",
    "BASE ARRAY NO VALUE AT THE POLES ??? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ds.regridder.horizontal(\"sfc_alb\", output_grid, tool=\"regrid2\")\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(16, 4))\n",
    "\n",
    "ds.sfc_alb.isel(time=0).plot(\n",
    "    ax=axes[0], vmin=-40, vmax=40, extend=\"both\", cmap=\"RdBu_r\"\n",
    ")\n",
    "\n",
    "output.sfc_alb.isel(time=0).plot(\n",
    "    ax=axes[1], vmin=-40, vmax=40, extend=\"both\", cmap=\"RdBu_r\"\n",
    ")\n",
    "axes[1].set_title(\"Output data\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_step_lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extraire une même variable, regrid toute la variable et combiner sur le nb de modèles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_field(ds, field: str):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    field_regridded = ds.regridder.horizontal(field, output_grid, tool=\"regrid2\")\n",
    "\n",
    "    return field_regridded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_aprp = dict_aprp.keys()\n",
    "\n",
    "\n",
    "fields = [\n",
    "    \"cld\",\n",
    "    \"sfc_alb\",\n",
    "    \"noncld\",\n",
    "    \"noncld_scat\",\n",
    "    \"noncld_abs\",\n",
    "    \"cld_amt\",\n",
    "    \"cld_scat\",\n",
    "    \"cld_abs\",\n",
    "]\n",
    "\n",
    "# initialize\n",
    "\n",
    "field = \"cld\"\n",
    "\n",
    "dict_aprp_regridded_full = {\n",
    "    key: dict_aprp[key].regridder.horizontal(field, output_grid, tool=\"regrid2\")\n",
    "    for key in keys_aprp\n",
    "}\n",
    "\n",
    "\n",
    "for field in fields[1:]:\n",
    "\n",
    "    # generate the dictionnary of all models for one field\n",
    "\n",
    "    dict_aprp_regridded_given_field = {\n",
    "        key: dict_aprp[key].regridder.horizontal(field, output_grid, tool=\"regrid2\")\n",
    "        for key in keys_aprp\n",
    "    }\n",
    "\n",
    "    # add this one field to the full dictionnary\n",
    "\n",
    "    dict_aprp_regridded_full = {\n",
    "        key: add_one_variable_to_dataset(\n",
    "            variable_name=field,\n",
    "            var_datarray=dict_aprp_regridded_given_field[key],\n",
    "            modify_data=True,\n",
    "            dataset=dict_aprp_regridded_full[key],\n",
    "        )\n",
    "        for key in keys_aprp\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_aprp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_aprp = [\n",
    "    \"BCC-ESM1.r1i1p1f1\",\n",
    "    \"UKESM1-0-LL.r1i1p1f4\",\n",
    "    \"CanESM5.r1i1p2f1\",\n",
    "    \"CNRM-CM6-1.r1i1p1f2\",\n",
    "    \"CNRM-ESM2-1.r1i1p1f2\",\n",
    "    \"ACCESS-ESM1-5.r1i1p1f1\",\n",
    "    \"MPI-ESM-1-2-HAM.r1i1p1f1\",\n",
    "    \"IPSL-CM6A-LR.r1i1p1f1\",\n",
    "    \"IPSL-CM6A-LR-INCA.r1i1p1f1\",\n",
    "    \"MIROC6.r1i1p1f1\",\n",
    "    \"MRI-ESM2-0.r1i1p1f1\",\n",
    "    \"GISS-E2-1-G.r1i1p1f1\",\n",
    "    \"CESM2.r1i1p1f1\",\n",
    "    \"NorESM2-LM.r1i1p1f1\",\n",
    "    \"NorESM2-MM.r1i1p1f1\",\n",
    "    \"GFDL-CM4.r1i1p1f1\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed for the concat function to work\n",
    "\n",
    "dict_aprp_regridded_full = {\n",
    "    key: dict_aprp_regridded_full[key]\n",
    "    .groupby(dict_aprp_regridded_full[key].time.dt.month)\n",
    "    .mean()\n",
    "    for key in keys_aprp\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make the entry average\n",
    "\n",
    "ensemble_aprp_avg = xr.concat(dict_aprp_regridded_full.values(), \"entry\").mean(\n",
    "    dim=\"entry\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT MAP OF APRP COMPONENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ensemble_aprp_avg\n",
    "\n",
    "fields = [\n",
    "    \"cld\",\n",
    "    \"sfc_alb\",\n",
    "    \"noncld\",\n",
    "    \"noncld_scat\",\n",
    "    \"noncld_abs\",\n",
    "    \"cld_amt\",\n",
    "    \"cld_scat\",\n",
    "    \"cld_abs\",\n",
    "]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "plt.suptitle(\"APRP Components\", fontsize=16, x=0, ha=\"left\")\n",
    "axes = fig.subplots(nrows=4, ncols=2, subplot_kw={\"projection\": ccrs.Robinson()})\n",
    "cnt = -1\n",
    "for row in range(4):\n",
    "    for col in range(2):\n",
    "        cnt += 1\n",
    "        var = fields[cnt]\n",
    "        avgmap = output.mean(\"month\")\n",
    "        avg = avgmap.spatial.average(var, axis=[\"X\", \"Y\"])[var].values\n",
    "        pl = avgmap[var].plot(\n",
    "            ax=axes[row, col],\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            vmin=-7.5,\n",
    "            vmax=7.5,\n",
    "            cmap=\"RdBu_r\",\n",
    "            add_colorbar=False,\n",
    "        )\n",
    "        axes[row, col].set_title(var + \" (\" + str(np.round(avg, 3)) + \")\")\n",
    "        axes[row, col].coastlines()\n",
    "\n",
    "plt.tight_layout(w_pad=2.5, h_pad=-2)\n",
    "\n",
    "fig.colorbar(\n",
    "    pl, ax=axes.ravel().tolist(), pad=0.02, shrink=0.5, aspect=15, label=\"W/m$^2$\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmip6-download",
   "language": "python",
   "name": "cmip6-download"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
