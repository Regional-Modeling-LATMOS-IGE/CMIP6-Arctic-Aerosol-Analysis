{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMIP6 Arctic Case Study : Compute the aerosol-cloud interaction effective radiative forcing\n",
    "\n",
    "## What this notebook holds \n",
    "\n",
    "This notebook aims at showing the effective radiative forcing that is caused by the aerosol burdens' levels of 2014.\n",
    "\n",
    "**WRITE ABOUT THE APRP METHOD !!!!**\n",
    "\n",
    "### The use of CMIP6 data\n",
    "\n",
    "We use two experiments realized during the CMIP6  : **piClim-control** and **piClim-aer**. These are both atmosphere-only climate model simulations in which sea surface temperatures (SSTs) and sea icea concentrations (SICs) are fixed at model-specific preindustrial climatological values. The description of the experiments can be found here : https://wcrp-cmip.github.io/CMIP6_CVs/docs/CMIP6_experiment_id.html. On the one hand, the **piClim-control** realization assumes aerosols burdens set to their preindustrial levels hence why it is dubbed as the control experiment. On the other hand, the **piClim-aer** realization uses present-day, present-day being 2014, aerosols burdens' levels.\n",
    "\n",
    "The variable used are listed and explicited below according to : https://clipc-services.ceda.ac.uk/dreq/mipVars.html. All the variables are monthly timeseries over 30 years . We use the monthly climatology of each of these variables.\n",
    "\n",
    "> <span style=\"color:SkyBlue\">**clt**</span>  : Total cloud area fraction (%) for the whole atmospheric column\n",
    ">\n",
    "> <span style=\"color:gold\">**rsdt / rldt**</span> : Shortwave / Longwave radiation ($W/m^{2}$) **incident** at the TOA\n",
    "> \n",
    "> <span style=\"color:orange\">**rsut / rlut**</span> : Shortwave / Longwave radiation ($W/m^{2}$) **going out**  at the TOA\n",
    ">\n",
    "> <span style=\"color:orangered\">**rsutcs / rlutcs**</span> : Shortwave / Longwave radiation ($W/m^{2}$) **going out**  at TOA for **clear-sky conditions**\n",
    "> \n",
    "> <span style=\"color:Orchid\">**rsds / rlds**</span> : Shortwave / Longwave **downwelling** radiation ($W/m^{2}$) at the surface\n",
    "> \n",
    "> <span style=\"color:Indigo \">**rsdscs / rldscs**</span>  : Shortwave / Longwave **downwelling** radiation ($W/m^{2}$) at the surface for **clear-sky conditions**\n",
    "> \n",
    "> <span style=\"color:YellowGreen\">**rsus / rlus**</span> : Shortwave / Longwave **upwelling** radiation ($W/m^{2}$) at the surface\n",
    ">\n",
    "> <span style=\"color:Darkgreen\">**rsuscs / rluscs**</span>: Shortwave / Longwave **upwelling** radiation ($W/m^{2}$) at the surface for **clear-sky conditions**\n",
    ">\n",
    "> **areacella** : For every grid, the latitude-dependent surface associated to each grid point.\n",
    "\n",
    "### Treatment of the clouds in the atmosphere column :\n",
    "\n",
    "We divide each grid cell into two distinct areas : the <span style=\"color:orange\">**clear-sky**</span> areas known as <span style=\"color:orange\">$cs$</span> and the cloudy areas known as <span style=\"color:purple\">**overcast**</span> or <span style=\"color:purple\">$oc$</span>. The variables we get from the models' outputs are only the <span style=\"color:orange\">**clear-sky**</span> and the <span style=\"color:red\">**all-sky**</span> variables though. \n",
    "\n",
    "For a given all-sky flux <span style=\"color:red\">$R$</span> value taken on a grid point, one can express it as a function of the clt written <span style=\"color:skyblue\">**c**</span>, the clear-sky flux written <span style=\"color:orange\">$R_{cs}$</span> and the overcast flux <span style=\"color:purple\">$R_{oc}$</span>. The total cloud fraction, <span style=\"color:skyblue\">**c**</span>, gives us the proportion of the atmosphere column that can be seen as cloudy from space. In turn the proportion of the atmosphere that knows a clear_sky is $1-$ <span style=\"color:skyblue\">**c**</span>. The expression derived is simply : \n",
    "\n",
    "> Equation (1) : $R = cR_{oc} + (1-c)R_{cs}$\n",
    "\n",
    "Therefore, the <span style=\"color:purple\">$R_{oc}$</span> can be computed as :\n",
    "\n",
    "> Equation (2) : $R_{oc} = \\frac{(R - (1-c)R_{cs})}{c}$\n",
    "\n",
    "Thus, <span style=\"color:purple\">$R_{oc}$</span> embodies the flux that can be found over cloudy areas. What's more, we make the hypothesis that **the noncloud atmospheric constituents absorb and scatter the same proportion of the radiation stream as they would if clouds were abruptly cleared from the region** (Taylor, K. E. et al. (2007)). This approximation means that, within an unit square meter of overcast atmosphere column, the observed <span style=\"color:purple\">$R_{oc}$</span> flux would be the sum of the clear sky flux, <span style=\"color:orange\">$R_{cs}$</span>, and of the flux coming out of the cloud. We call this flux <span style=\"color:blue\">$R_{cloud}$</span>.\n",
    "\n",
    "Therefore, by taking the difference between the overcast flux and the clear-sky flux, one could grasp the sole contribution of the clouds on the grid cell. As a result, the cloud contribution to the all-sky flux <span style=\"color:blue\">$R_{cloud}$</span> can be obtained through the following equation :\n",
    "\n",
    "> Equation (3) : $R_{cloud} = R_{oc} - R_{cs}$\n",
    "\n",
    "The following figure explicits the decomposition behind our hypothesis :\n",
    "\n",
    "![title](img/clouds.svg)\n",
    "\n",
    "In addition, our hypothesis allows us to introduce another decomposition of the all-sky flux :\n",
    "\n",
    "> $R = cR_{oc} + (1-c)R_{cs}$\n",
    "> \n",
    "> $R = c(R_{oc} - R_{cs}) + R_{cs}$\n",
    "> \n",
    "> Equation (4) : $R = c$<span style=\"color:blue\">$R_{cloud}$</span> + <span style=\"color:orange\">$R_{cs}$</span>\n",
    "\n",
    "### Computing the variation of a flux between the two experiments \n",
    "\n",
    "Having the expression of any all-sky flux in function of the <span style=\"color:purple\">**overcast**</span> and <span style=\"color:orange\">**clear-sky**</span> fluxes, one can derive $\\Delta R$, which is the contribution of the 2014 aerosols' content in the atmosphere compared to the pre-industrial concentrations. \n",
    "\n",
    "As a reminder, a full-sky flux of one experiment, noted as $exp$, can be expressed as in the following.\n",
    "\n",
    "> $[R]_{exp} = [c]_{exp}[R_{oc}]_{exp} + (1-[c]_{exp})[R_{cs}]_{exp}$\n",
    "\n",
    "We may then derive $\\Delta R$. Any expression noted with a $\\Delta$ is the difference between the $aer$ and the $ctrl$ experiment. Without any approximation, one can find that $\\Delta R$ can be written as the differential of R where the fluxes and total cloud fractions are taken as their mean values between the two experiments. Indeed, by giving $c = \\frac{[c]_{aer}+[c]_{ctrl}}{2}$, $R_{oc} = \\frac{[R_{oc}]_{aer}+[R_{oc}]_{ctrl}}{2}$ and $R_{cs} = \\frac{[R_{cs}]_{aer}+[R_{cs}]_{ctrl}}{2}$,  we find the expression written below.\n",
    "\n",
    "> $\\Delta R = R_{aer} - R_{control} $\n",
    ">\n",
    "> $\\Delta R = [c]_{aer}[R_{oc}]_{aer} + (1-[c]_{aer})[R_{cs}]_{aer}$ - $[R]_{ctrl} = [c]_{ctr}[R_{oc}]_{ctrl} + (1-[c]_{ctrl})[R_{cs}]_{ctrl}$\n",
    ">\n",
    "> $\\Delta R =$ <span style=\"color:orange\">$\\Delta R_{cs}$</span> + <span style=\"color:SkyBlue\">$\\Delta c (R_{oc} - R_{cs})$</span> + <span style=\"color:SteelBlue\">$c (\\Delta R_{oc} - \\Delta R_{cs})$</span>\n",
    "\n",
    "From this equation, we get three different effects of changing the aerosols' burdens on the all-sky flux.\n",
    "\n",
    "> $\\Delta R_{cs}$ : the variation in R due to <span style=\"color:orange\">**the effect of aerosols in the absence of clouds**</span>\n",
    "> \n",
    "> <span style=\"color:SkyBlue\">$\\Delta c (R_{oc} - R_{cs})$</span> : the mean change in R caused by <span style=\"color:SkyBlue\">**the variation of the total cloud-cover**</span>\n",
    "> \n",
    "> <span style=\"color:SteelBlue\">$c (\\Delta R_{oc} - \\Delta R_{cs})$</span> : the mean contribution in R of <span style=\"color:SteelBlue\">**the variation in the clouds' flux for a mean cloud coverage**</span>\n",
    "\n",
    "The two final terms sum up the **cloud contribution** in the difference between the aerosol and control experiments. However, as noted in Taylor, K. E. et al. (2007), these two effects cannot be considered as the cloud feedback. Actually, even if the clouds variables $c$ and $R_{oc}$ do not vary making $\\Delta c$ and $\\Delta R_{oc}$ zero, a sole variation in the clear-sky direct effect will make the final term non-zero.\n",
    "\n",
    "### APRP METHOD FOR THE SW\n",
    "\n",
    "\n",
    "Done by Lucas Giboni,\n",
    "\n",
    "Reference :\n",
    "\n",
    "Taylor, K. E. et al. (2007), Estimating shortwave radiative forcing and response in \n",
    "    climate models, J. Clim., 20(11), 2530-2543, doi:10.1175/JCLI4143.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD AND NAVIGATE THROUGH THE DATA ###\n",
    "\n",
    "import os  # to get access to commands related to path setting and creation of directories\n",
    "\n",
    "import intake_esgf  # this gives us access to the ESGF catalog to make queries\n",
    "\n",
    "### DATA OBJECTS AND ASSOCIATED COMPUTATION ###\n",
    "\n",
    "import numpy as np  # to handle numpy arrays and the associated tools\n",
    "\n",
    "import xarray as xr  # to manage the data\n",
    "\n",
    "import xcdat as xc  # to handle climate model outputs with xarray\n",
    "\n",
    "import pandas as pd  # to create and handle tables in python\n",
    "\n",
    "### HOMEMADE LIBRARIES ###\n",
    "\n",
    "from utilities.download.load_cmip6 import loading_cmip6 # function to load the raw data\n",
    "\n",
    "from utilities.download.folders_handle.create import create_dir  # function to create a cleaned downloading directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INITIALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================ DEFINE THE FOLDERS WHERE IS STORED THE DATA ================ #\n",
    "\n",
    "### DEFINE THE HOME DIRECTORY ###\n",
    "\n",
    "## Home directory ##\n",
    "\n",
    "homedir_path = os.path.expanduser(\"~\")\n",
    "\n",
    "### DEFINE WHERE IS THE DOWNLOADED RAW DATA ###\n",
    "\n",
    "## Parent directory ##\n",
    "\n",
    "parent_path_download = homedir_path + \"/certainty-data\"\n",
    "\n",
    "## Name of the created folder ##\n",
    "\n",
    "download_folder_name = \"CMIP6-DATA\"\n",
    "\n",
    "### DEFINE WHERE TO SAVE THE CLIMATOLOGIES ###\n",
    "\n",
    "## Parent directory ##\n",
    "\n",
    "parent_path_save = homedir_path + \"/certainty-data/CMIP6-DATA/\"\n",
    "\n",
    "## Name of the created folder ##\n",
    "\n",
    "saving_folder_name = \"treated-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CMIP6 data will be searched at the path : ['/home/jovyan/certainty-data/CMIP6-DATA']\n",
      "\n",
      "The search criterias are : ['piClim-control', 'piClim-aer']\n",
      "['clt', 'rsdt', 'rsut', 'rsutcs', 'rsds', 'rsus', 'rsdscs', 'rsuscs', 'rlut', 'rlutcs', 'rlds', 'rlus']\n",
      "Amon\n",
      "\n",
      "Filling the catalog with the search criterias...\n",
      "\n",
      "Downloading and/or loading the data dictionnary\n",
      "\n",
      "Downloading and/or loading the areacella dictionnary\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### LOADING THE DATA ????\n",
    "\n",
    "dict_cmip6, dict_areacella = loading_cmip6(\n",
    "    parent_path=parent_path,\n",
    "    downloading_folder_name=downloading_folder_name,\n",
    "    do_we_clear=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERATE SIMPLER DICTIONNARY KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "### GENERATE SIMPLER DICTIONNARY KEYS ###\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERATE THE CMIP6 CLIMATOLOGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "### GENERATE CMIP6 CLIMATOLOGY ###\n",
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "yes\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     31\u001b[39m var_datarray = dict_cmip6[key_with_var_full]\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# retrieve the areacella #\u001b[39;00m\n\u001b[32m     34\u001b[39m \n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# areacella_datarray =\u001b[39;00m\n\u001b[32m     36\u001b[39m \n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# generate or update the dataset for the given exp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m dataset_given_exp = \u001b[43madd_one_variable_to_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariable_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_datarray\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvar_datarray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodify_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodify_data\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# now the dataset already exists\u001b[39;00m\n\u001b[32m     45\u001b[39m modify_data = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36madd_one_variable_to_dataset\u001b[39m\u001b[34m(variable_name, var_datarray, modify_data, dataset)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m### DEFINITION\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \u001b[33;03mDATA_AER : XARRAY | dataset holding the climatology of the given variable for the aerosol experiment\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m### INITIALIZATION ###\u001b[39;00m\n\u001b[32m     34\u001b[39m \n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m## Retrieving the path associated with the inputs if it exists ##\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m \n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m## Produce climatologies for each experiment ##\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m var_climatology = \u001b[43mvar_datarray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtemporal\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclimatology\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmonth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweighted\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     45\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# we generate a monthly climatology\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# this groupby method of xarray regroups all the points within the same month together\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# we then decide what to do with these ensembles for each month : here we compute the mean for each month\u001b[39;00m\n\u001b[32m     49\u001b[39m \n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m### ADDING THE VARIABLE TO THE DATASETS ###\u001b[39;00m\n\u001b[32m     51\u001b[39m \n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m## Check wether we need to initialize the datasets or not : if so initialize them if not fill the provided ones ##\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m modify_data:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-conda-envs/cmip6-analysis/lib/python3.13/site-packages/xcdat/temporal.py:616\u001b[39m, in \u001b[36mTemporalAccessor.climatology\u001b[39m\u001b[34m(self, data_var, freq, weighted, keep_weights, reference_period, season_config)\u001b[39m\n\u001b[32m    437\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns a Dataset with the climatology of a data variable.\u001b[39;00m\n\u001b[32m    438\u001b[39m \n\u001b[32m    439\u001b[39m \u001b[33;03mData is grouped into the labeled time point for the averaging operation.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    612\u001b[39m \u001b[33;03m}\u001b[39;00m\n\u001b[32m    613\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    614\u001b[39m \u001b[38;5;28mself\u001b[39m._set_data_var_attrs(data_var)\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_averager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclimatology\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweighted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreference_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseason_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-conda-envs/cmip6-analysis/lib/python3.13/site-packages/xcdat/temporal.py:879\u001b[39m, in \u001b[36mTemporalAccessor._averager\u001b[39m\u001b[34m(self, data_var, mode, freq, weighted, keep_weights, reference_period, season_config)\u001b[39m\n\u001b[32m    877\u001b[39m     dv_avg = \u001b[38;5;28mself\u001b[39m._average(ds, data_var)\n\u001b[32m    878\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mode \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mgroup_average\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mclimatology\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdepartures\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m     dv_avg = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_group_average\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_var\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;66;03m# The original time dimension is dropped from the dataset because\u001b[39;00m\n\u001b[32m    882\u001b[39m \u001b[38;5;66;03m# it becomes obsolete after the data variable is averaged. When the\u001b[39;00m\n\u001b[32m    883\u001b[39m \u001b[38;5;66;03m# averaged data variable is added to the dataset, the new time dimension\u001b[39;00m\n\u001b[32m    884\u001b[39m \u001b[38;5;66;03m# and its associated coordinates are also added.\u001b[39;00m\n\u001b[32m    885\u001b[39m ds = ds.drop_dims(\u001b[38;5;28mself\u001b[39m.dim)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-conda-envs/cmip6-analysis/lib/python3.13/site-packages/xcdat/temporal.py:1507\u001b[39m, in \u001b[36mTemporalAccessor._group_average\u001b[39m\u001b[34m(self, ds, data_var)\u001b[39m\n\u001b[32m   1504\u001b[39m \u001b[38;5;28mself\u001b[39m._weights = \u001b[38;5;28mself\u001b[39m._get_weights(time_bounds)\n\u001b[32m   1506\u001b[39m \u001b[38;5;66;03m# Weight the data variable.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m \u001b[43mdv\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_weights\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[38;5;66;03m# Ensure missing data (`np.nan`) receives no weight (zero). To\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;66;03m# achieve this, first broadcast the one-dimensional (temporal\u001b[39;00m\n\u001b[32m   1511\u001b[39m \u001b[38;5;66;03m# dimension) shape of the `weights` DataArray to the\u001b[39;00m\n\u001b[32m   1512\u001b[39m \u001b[38;5;66;03m# multi-dimensional shape of its corresponding data variable.\u001b[39;00m\n\u001b[32m   1513\u001b[39m weights, _ = xr.broadcast(\u001b[38;5;28mself\u001b[39m._weights, dv)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-conda-envs/cmip6-analysis/lib/python3.13/site-packages/xarray/core/_typed_ops.py:778\u001b[39m, in \u001b[36mDataArrayOpsMixin.__imul__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    777\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__imul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: DaCompatible) -> Self:  \u001b[38;5;66;03m# type:ignore[misc]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inplace_binary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimul\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-conda-envs/cmip6-analysis/lib/python3.13/site-packages/xarray/core/dataarray.py:4882\u001b[39m, in \u001b[36mDataArray._inplace_binary_op\u001b[39m\u001b[34m(self, other, f)\u001b[39m\n\u001b[32m   4880\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   4881\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.coords._merge_inplace(other_coords):\n\u001b[32m-> \u001b[39m\u001b[32m4882\u001b[39m         \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_variable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4883\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MergeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m   4884\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[32m   4885\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAutomatic alignment is not supported for in-place operations.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   4886\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mConsider aligning the indices manually or using a not-in-place operation.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   4887\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSee https://github.com/pydata/xarray/issues/3910 for more explanations.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4888\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-conda-envs/cmip6-analysis/lib/python3.13/site-packages/xarray/core/_typed_ops.py:1206\u001b[39m, in \u001b[36mVariableOpsMixin.__imul__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m   1205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__imul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: VarCompatible) -> Self:  \u001b[38;5;66;03m# type:ignore[misc]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1206\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inplace_binary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimul\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-conda-envs/cmip6-analysis/lib/python3.13/site-packages/xarray/core/variable.py:2339\u001b[39m, in \u001b[36mVariable._inplace_binary_op\u001b[39m\u001b[34m(self, other, f)\u001b[39m\n\u001b[32m   2337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, xr.Dataset):\n\u001b[32m   2338\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot add a Dataset to a Variable in-place\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2339\u001b[39m self_data, other_data, dims = \u001b[43m_broadcast_compat_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dims != \u001b[38;5;28mself\u001b[39m.dims:\n\u001b[32m   2341\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdimensions cannot change for in-place operations\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-conda-envs/cmip6-analysis/lib/python3.13/site-packages/xarray/core/variable.py:2937\u001b[39m, in \u001b[36m_broadcast_compat_data\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m   2934\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mhasattr\u001b[39m(other, attr) \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mdims\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m]):\n\u001b[32m   2935\u001b[39m     \u001b[38;5;66;03m# `other` satisfies the necessary Variable API for broadcast_variables\u001b[39;00m\n\u001b[32m   2936\u001b[39m     new_self, new_other = _broadcast_compat_variables(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[32m-> \u001b[39m\u001b[32m2937\u001b[39m     self_data = \u001b[43mnew_self\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\n\u001b[32m   2938\u001b[39m     other_data = new_other.data\n\u001b[32m   2939\u001b[39m     dims = new_self.dims\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-conda-envs/cmip6-analysis/lib/python3.13/site-packages/xarray/core/variable.py:416\u001b[39m, in \u001b[36mVariable.data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._data, indexing.ExplicitlyIndexed):\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.values\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-conda-envs/cmip6-analysis/lib/python3.13/site-packages/xarray/core/indexing.py:836\u001b[39m, in \u001b[36mMemoryCachedArray.get_duck_array\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    835\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m836\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ensure_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    837\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.array.get_duck_array()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-conda-envs/cmip6-analysis/lib/python3.13/site-packages/xarray/core/indexing.py:833\u001b[39m, in \u001b[36mMemoryCachedArray._ensure_cached\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_ensure_cached\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m     \u001b[38;5;28mself\u001b[39m.array = as_indexable(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-conda-envs/cmip6-analysis/lib/python3.13/site-packages/xarray/core/indexing.py:790\u001b[39m, in \u001b[36mCopyOnWriteArray.get_duck_array\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-conda-envs/cmip6-analysis/lib/python3.13/site-packages/xarray/core/indexing.py:660\u001b[39m, in \u001b[36mLazilyIndexedArray.get_duck_array\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    655\u001b[39m \u001b[38;5;66;03m# self.array[self.key] is now a numpy array when\u001b[39;00m\n\u001b[32m    656\u001b[39m \u001b[38;5;66;03m# self.array is a BackendArray subclass\u001b[39;00m\n\u001b[32m    657\u001b[39m \u001b[38;5;66;03m# and self.key is BasicIndexer((slice(None, None, None),))\u001b[39;00m\n\u001b[32m    658\u001b[39m \u001b[38;5;66;03m# so we need the explicit check for ExplicitlyIndexed\u001b[39;00m\n\u001b[32m    659\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array, ExplicitlyIndexed):\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m     array = \u001b[43marray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _wrap_numpy_scalars(array)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-conda-envs/cmip6-analysis/lib/python3.13/site-packages/xarray/coding/common.py:76\u001b[39m, in \u001b[36m_ElementwiseFunctionArray.get_duck_array\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.func(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-conda-envs/cmip6-analysis/lib/python3.13/site-packages/xarray/core/indexing.py:653\u001b[39m, in \u001b[36mLazilyIndexedArray.get_duck_array\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    649\u001b[39m     array = apply_indexer(\u001b[38;5;28mself\u001b[39m.array, \u001b[38;5;28mself\u001b[39m.key)\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    651\u001b[39m     \u001b[38;5;66;03m# If the array is not an ExplicitlyIndexedNDArrayMixin,\u001b[39;00m\n\u001b[32m    652\u001b[39m     \u001b[38;5;66;03m# it may wrap a BackendArray so use its __getitem__\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     array = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[38;5;66;03m# self.array[self.key] is now a numpy array when\u001b[39;00m\n\u001b[32m    656\u001b[39m \u001b[38;5;66;03m# self.array is a BackendArray subclass\u001b[39;00m\n\u001b[32m    657\u001b[39m \u001b[38;5;66;03m# and self.key is BasicIndexer((slice(None, None, None),))\u001b[39;00m\n\u001b[32m    658\u001b[39m \u001b[38;5;66;03m# so we need the explicit check for ExplicitlyIndexed\u001b[39;00m\n\u001b[32m    659\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array, ExplicitlyIndexed):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-conda-envs/cmip6-analysis/lib/python3.13/site-packages/xarray/backends/netCDF4_.py:103\u001b[39m, in \u001b[36mNetCDF4ArrayWrapper.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexplicit_indexing_adapter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIndexingSupport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOUTER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-conda-envs/cmip6-analysis/lib/python3.13/site-packages/xarray/core/indexing.py:1014\u001b[39m, in \u001b[36mexplicit_indexing_adapter\u001b[39m\u001b[34m(key, shape, indexing_support, raw_indexing_method)\u001b[39m\n\u001b[32m    992\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Support explicit indexing by delegating to a raw indexing method.\u001b[39;00m\n\u001b[32m    993\u001b[39m \n\u001b[32m    994\u001b[39m \u001b[33;03mOuter and/or vectorized indexers are supported by indexing a second time\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1011\u001b[39m \u001b[33;03mIndexing result, in the form of a duck numpy-array.\u001b[39;00m\n\u001b[32m   1012\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1013\u001b[39m raw_key, numpy_indices = decompose_indexer(key, shape, indexing_support)\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m result = \u001b[43mraw_indexing_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_key\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m numpy_indices.tuple:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;66;03m# index the loaded duck array\u001b[39;00m\n\u001b[32m   1017\u001b[39m     indexable = as_indexable(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-conda-envs/cmip6-analysis/lib/python3.13/site-packages/xarray/backends/netCDF4_.py:116\u001b[39m, in \u001b[36mNetCDF4ArrayWrapper._getitem\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.datastore.lock:\n\u001b[32m    115\u001b[39m         original_array = \u001b[38;5;28mself\u001b[39m.get_array(needs_lock=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         array = \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    118\u001b[39m     \u001b[38;5;66;03m# Catch IndexError in netCDF4 and return a more informative\u001b[39;00m\n\u001b[32m    119\u001b[39m     \u001b[38;5;66;03m# error message.  This is most often called when an unsorted\u001b[39;00m\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# indexer is used before the data is loaded from disk.\u001b[39;00m\n\u001b[32m    121\u001b[39m     msg = (\n\u001b[32m    122\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe indexing operation you are attempting to perform \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    123\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mis not valid on netCDF4.Variable object. Try loading \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    124\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myour data into memory first by calling .load().\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    125\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# go through each global experiment key and add the 12 variable\n",
    "\n",
    "dict_cmip6_clim = {}\n",
    "\n",
    "# we have selected one model / variant / exp !!\n",
    "\n",
    "for key in keys_without_variable_unique:\n",
    "\n",
    "    # initialize the dataset with the first variable\n",
    "\n",
    "    var = variable_id[0]\n",
    "\n",
    "    # it does not exists yet\n",
    "\n",
    "    modify_data = False\n",
    "\n",
    "    # copy the key without variable\n",
    "\n",
    "    key_with_var = key\n",
    "\n",
    "    # add the variable name\n",
    "\n",
    "    key_with_var[-2] = var\n",
    "\n",
    "    # add the given variable to the key\n",
    "\n",
    "    key_with_var_full = \".\".join(key_with_var)\n",
    "\n",
    "    # retrieve the variable data array\n",
    "\n",
    "    var_datarray = dict_cmip6[key_with_var_full]\n",
    "\n",
    "    # retrieve the areacella #\n",
    "\n",
    "    # areacella_datarray =\n",
    "\n",
    "    # generate or update the dataset for the given exp\n",
    "\n",
    "    dataset_given_exp = add_one_variable_to_dataset(\n",
    "        variable_name=var, var_datarray=var_datarray, modify_data=modify_data\n",
    "    )\n",
    "\n",
    "    # now the dataset already exists\n",
    "\n",
    "    modify_data = True\n",
    "\n",
    "    # we already initialized the dataset\n",
    "\n",
    "    # go through the remaining variables\n",
    "\n",
    "    for var in variable_id[1:]:\n",
    "\n",
    "        key_with_var = key\n",
    "\n",
    "        key_with_var[-2] = var\n",
    "\n",
    "        # add the given variable to the key\n",
    "\n",
    "        key_with_var_full = \".\".join(key_with_var)\n",
    "\n",
    "        # retrieve the variable data array\n",
    "\n",
    "        var_datarray = dict_cmip6[key_with_var_full]\n",
    "\n",
    "        # update the dataset for the given exp\n",
    "\n",
    "        add_one_variable_to_dataset(\n",
    "            variable_name=var,\n",
    "            var_datarray=var_datarray,\n",
    "            modify_data=modify_data,\n",
    "            dataset=dataset_given_exp,\n",
    "        )\n",
    "\n",
    "    # retrieving key information\n",
    "\n",
    "    source_id = key[2]\n",
    "\n",
    "    experiment_id = key[3]\n",
    "\n",
    "    member_id = key[4]\n",
    "\n",
    "    grid_label = key[-1]\n",
    "\n",
    "    # access the associated areacella entry in dict_areacella\n",
    "\n",
    "    # build the key\n",
    "\n",
    "    key_areacella = \".\".join([source_id, member_id, grid_label])\n",
    "\n",
    "    # retrieve areacella\n",
    "\n",
    "    areacella_datarray = dict_areacella[key_areacella]\n",
    "\n",
    "    #  update the dataset for the given exp with the associated areacella\n",
    "\n",
    "    dataset_given_exp[\"areacella\"] = (\n",
    "            (\"lat\", \"lon\"),\n",
    "            areacella_datarray[\"areacella\"].values,\n",
    "        )\n",
    "\n",
    "    # create the new key\n",
    "\n",
    "    new_simpler_key_given_exp = \".\".join([source_id, member_id, experiment_id])\n",
    "\n",
    "    # add the dataset to the dictionnary\n",
    "\n",
    "    dict_cmip6_clim[new_simpler_key_given_exp] = dataset_given_exp\n",
    "\n",
    "    # clear the memory\n",
    "\n",
    "    del dataset_given_exp\n",
    "\n",
    "\n",
    "dict_cmip6.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'lat' coordinate variable is missing a 'units' attribute. Assuming 'units' is 'degrees_north'.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"output = APRP(\n",
    "    dict_cmip6_clim[\"IPSL-CM6A-LR.r1i1p1f1.piClim-control\"],\n",
    "    dict_cmip6_clim[\"IPSL-CM6A-LR.r1i1p1f1.piClim-aer\"],\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/certainty-data/CMIP6-DATA/treated-data'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create given folder\n",
    "\n",
    "homedir_path = os.path.expanduser(\"~\")\n",
    "\n",
    "## Parent directory ##\n",
    "\n",
    "parent_path = homedir_path + \"/certainty-data/CMIP6-DATA/\"\n",
    "\n",
    "saving_folder_name = \"treated-data\"\n",
    "\n",
    "\n",
    "saving_path = create_dir(parent_path=parent_path, name=saving_folder_name, clear=True)\n",
    "\n",
    "saving_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_keys = list(dict_cmip6_clim.keys())\n",
    "\n",
    "n_keys = len(list_keys)\n",
    "\n",
    "paths = np.empty(n_keys, dtype=object)  # otherwise it truncates the str\n",
    "\n",
    "\n",
    "## Home directory ##\n",
    "\n",
    "for ii, key in enumerate(list_keys):\n",
    "\n",
    "    splitted_key = key.split(\".\")\n",
    "\n",
    "    full_name = \"_\".join(splitted_key)\n",
    "\n",
    "    filename = full_name + \".nc\"\n",
    "\n",
    "    saving_path_given_exp = create_dir(\n",
    "        parent_path=saving_path, name=full_name, clear=True\n",
    "    )\n",
    "\n",
    "    path_to_nc = saving_path_given_exp + \"/\" + filename\n",
    "\n",
    "    dict_cmip6_clim[key].to_netcdf(path=path_to_nc)\n",
    "\n",
    "    paths[ii] = path_to_nc\n",
    "\n",
    "# need to save path_to_nc linked to a dictionnary key into a pandas dataframe key\n",
    "\n",
    "# create a pandas dataframe from a dictionnary\n",
    "\n",
    "key_paths_dict = {\"key\": list_keys, \"path\": paths}\n",
    "\n",
    "key_paths_table = pd.DataFrame(key_paths_dict)\n",
    "\n",
    "# save it\n",
    "\n",
    "key_paths_table.to_pickle(saving_path + \"/\" + \"key_paths_table.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dictionnary\n",
    "\n",
    "dict_cmip6_clim = {}\n",
    "\n",
    "# loading the data once it is saved\n",
    "\n",
    "key_paths_table = pd.read_pickle(saving_path + \"/\" + \"key_paths_table.pkl\")\n",
    "\n",
    "# rebuild the dictionnary\n",
    "\n",
    "list_keys = key_paths_table[\"key\"].to_list()\n",
    "\n",
    "paths = key_paths_table[\"path\"].to_list()\n",
    "\n",
    "for ii, key in enumerate(list_keys):\n",
    "\n",
    "    path_to_nc = paths[ii]\n",
    "\n",
    "    dict_cmip6_clim[key] = xr.open_dataset(path_to_nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cmip6-analysis]",
   "language": "python",
   "name": "conda-env-cmip6-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
